#!/usr/bin/env python3
import argparse
import copy
import json
import math
import os
import os.path
import random
import signal
import sys
from functools import partial

import atom_calibration.calibration.patterns_config as patterns
import atom_core.naming
import cv2
import numpy as np
# own packages
import OptimizationUtils.OptimizationUtils as OptimizationUtils
import ros_numpy
# 3rd-party
import rospy
import sensor_msgs.point_cloud2 as pc2
import tf
from atom_calibration.calibration.getters_and_setters import (
    getterCameraIntrinsics, getterTransform, setterCameraIntrinsics,
    setterTransform)
from atom_calibration.calibration.objective_function import (
    getPointsInSensorAsNPArray, objectiveFunction)
from atom_calibration.collect.label_messages import (
    convertDepthImage16UC1to32FC1, convertDepthImage32FC1to16UC1,
    imageShowUInt16OrFloat32OrBool)
from atom_calibration.dataset_playback.depth_manual_labeling import (
    clickedPointsCallback, clickedPointsReset)
from atom_calibration.dataset_playback.lidar3d_manual_labelling import *
from atom_calibration.dataset_playback.visualization import (
    setupVisualization, visualizationFunction)
from atom_core.config_io import readXacroFile, uriReader
from atom_core.dataset_io import (NpEncoder, addNoiseToInitialGuess,
                                  createDataFile, filterCollectionsFromDataset,
                                  filterSensorsFromDataset,
                                  getPointCloudMessageFromDictionary,
                                  loadResultsJSON, saveResultsJSON, walk)
from atom_core.naming import generateKey, generateName
from colorama import Back, Fore, Style
from cv_bridge import CvBridge
from geometry_msgs.msg import PointStamped
from pynput import keyboard
from rospy_message_converter import message_converter
from sensor_msgs.msg import PointCloud2
from sqlalchemy import false

# global variables  ... are forbidden

# -------------------------------------------------------------------------------
# --- FUNCTIONS
# -------------------------------------------------------------------------------

# TODO #390 We should talk to Daniel to understand why sorting was a problem.
# Daniel: I had to copy this functions because in the atomv_core.dataset_io we are sorting the keys! We should not sort the keys!!!
# def saveResultsJSON(output_file, dataset_in, freeze_dataset=False):
#     if freeze_dataset:  # to make sure our changes only affect the dictionary to save
#         dataset = copy.deepcopy(dataset_in)
#     else:
#         dataset = dataset_in
#     output_folder = os.path.dirname(output_file)
#
#     # Process the dataset to remove data from the data fields and, if needed, write the files.
#     for collection_key, collection in dataset['collections'].items():
#         for sensor_key, sensor in dataset['sensors'].items():
#             createDataFile(dataset, collection_key, sensor,
#                            sensor_key, output_folder)
#
#         # Do the same for additional data topics ...
#         # for description, sensor in dataset['additional_sensor_data'].items():
#         #     createDataFile(dataset_in, collection_key, sensor, description, output_folder, 'additional_data')
#
#     createJSONFile(output_file, dataset)  # write dictionary to json
#
#
# def createJSONFile(output_file, input):
#     """
#     Creates the json file containing the results data.
#     :param output_file: output file.
#     :param input: input dictionary containing the data.
#     """
#     D = copy.deepcopy(input)
#     walk(D)
#
#     print("Saving the json output file to " + str(output_file) +
#           ", please wait, it could take a while ...")
#     f = open(output_file, 'w')
#     # to get only four decimal places on the json file
#     json.encoder.FLOAT_REPR = lambda f: ("%.6f" % f)
#     # print >> f, json.dumps(D, indent=2, sort_keys=True)
#     f.write(json.dumps(D, indent=2, cls=NpEncoder))
#
#     f.close()
#     print("Completed.")

# keyboard listener


def keyPressed(key, selection, dataset, args):
    # Shortcut variables
    idx_collection = int(selection['collection_key'])
    idx_max_collection = len(dataset['collections'].keys()) - 1
    output_file = '/'.join(args['json_file'].split('/')
                           [:-1]) + '/dataset_corrected.json'

    # Convert from type to string to keep uniform.
    key = str(key)
    if key == 'Key.right':  # Save and move to collection + 1.
        if idx_collection < idx_max_collection:
            selection['previous_collection_key'] = selection['collection_key']
            selection['collection_key'] = str(idx_collection + 1)
            print('Changed selected_collection_key to ' +
                  selection['collection_key'])
            saveResultsJSON(output_file, dataset, freeze_dataset=True)
        else:
            print(Fore.RED + 'This is the last collection!!' + Fore.RESET)
    elif key == 'Key.left':  # Save and move to collection - 1.
        if idx_collection > 0:
            selection['previous_collection_key'] = selection['collection_key']
            selection['collection_key'] = str(idx_collection - 1)
            print('Changed selected_collection_key to ' +
                  selection['collection_key'])
            saveResultsJSON(output_file, dataset, freeze_dataset=True)
        else:
            print(Fore.RED + 'This is the first collection!!' + Fore.RESET)
    elif key == "'s'":  # Saves dataset.
        saveResultsJSON(output_file, dataset, freeze_dataset=True)
        print('A new dataset was saved in ' + output_file)
    elif key == "'q'":  # Saves dataset and quits.
        saveResultsJSON(output_file, dataset, freeze_dataset=True)
        print('A new dataset was saved in ' + output_file)

        print('Exiting ...')
        selection['exit'] = True


# -------------------------------------------------------------------------------
# --- MAIN
# -------------------------------------------------------------------------------
def main():
    ap = argparse.ArgumentParser()
    ap = OptimizationUtils.addArguments(ap)  # OptimizationUtils arguments
    ap.add_argument("-json", "--json_file",
                    help="Json file containing input dataset.", type=str, required=True)
    ap.add_argument("-v", "--verbose", help="Be verbose",
                    action='store_true', default=False)
    ap.add_argument("-rv", "--ros_visualization",
                    help="Publish ros visualization markers.", action='store_true')
    ap.add_argument("-si", "--show_images", help="shows images for each camera",
                    action='store_true', default=False)
    ap.add_argument("-ajf", "--all_joints_fixed",
                    help="Assume all joints are fixed and because of that draw a single robot mesh. Overrides "
                         "automatic detection of static robot.",
                    action='store_true', default=False)
    ap.add_argument("-uic", "--use_incomplete_collections",
                    help="Remove any collection which does not have a detection for all sensors.",
                    action='store_true', default=False)
    ap.add_argument("-rpd", "--remove_partial_detections",
                    help="Remove detected labels which are only partial. Used or the Charuco.",
                    action='store_true', default=False)
    ap.add_argument("-ssf", "--sensor_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a sensor name as input and '
                         'returns True or False to indicate if the sensor should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: name in ["left_laser", "frontal_camera"] , to load only '
                         'sensors left_laser and frontal_camera')
    ap.add_argument("-csf", "--collection_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a collection name as input and '
                         'returns True or False to indicate if the collection should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: int(name) > 5 , to load only collections 6, 7, and onward.')
    ap.add_argument('-oj', '--output_json', help='Full path to output json file.', type=str, required=False,
                    default=None)
    ap.add_argument("-ow", "--overwrite",
                    help="Overwrites the data_corrected.json without asking for permission.", action='store_true')

    # Roslaunch adds two arguments (__name and __log) that break our parser. Lets remove those.
    arglist = [x for x in sys.argv[1:] if not x.startswith('__')]
    args = vars(ap.parse_args(args=arglist))

    # ---------------------------------------
    # --- INITIALIZATION Read data from file
    # ---------------------------------------
    # Loads a json file containing the detections. Returned json_file has path resolved by urireader.
    dataset, json_file = loadResultsJSON(
        args['json_file'], args['collection_selection_function'])

    # ---------------------------------------
    # --- Filter some collections and / or sensors from the dataset
    # ---------------------------------------
    dataset = filterCollectionsFromDataset(dataset, args)  # filter collections
    output_file = '/'.join(args['json_file'].split('/')
                           [:-1]) + '/dataset_corrected.json'
    if os.path.exists(output_file) and args['json_file'] != output_file and not args['overwrite']:
        ans = input(
            'The file dataset_corrected.json already exists. Do you want to overwrite? (Y/n)')
        if ans.lower() == 'n':
            sys.exit(0)

    # Create the chessboard dataset must be called before deleting the sensors to cope with the possibility of
    # setting up an optimization without cameras. For now we MUST have a camera to estimate the initial parameters
    # related to the pattern pose (we use solve PNP for a camera).
    # TODO: Solve this strange dependency.
    dataset['patterns'] = patterns.createPatternLabels(args, dataset)

    dataset = filterSensorsFromDataset(dataset, args)  # filter sensors

    print('Loaded dataset containing ' + str(len(dataset['sensors'].keys())) + ' sensors and ' + str(
        len(dataset['collections'].keys())) + ' collections.')

    # ---------------------------------------
    # --- Store initial values for transformations to be optimized
    # ---------------------------------------
    for collection_key, collection in dataset['collections'].items():
        initial_transform_key = generateName('transforms', suffix='ini')
        collection[initial_transform_key] = copy.deepcopy(
            collection['transforms'])
        for transform_key, transform in collection[initial_transform_key].items():
            transform['parent'] = generateName(
                transform['parent'], suffix='ini')
            transform['child'] = generateName(transform['child'], suffix='ini')

    # ---------------------------------------
    # --- Define selected collection key.
    # ---------------------------------------
    # Lets start with the first key on the collections dictionary.
    # Data structure used to save the state of navigation throughout the collections in the dataset.
    selection = {'collection_key': list(dataset['collections'].keys())[0], 'previous_collection_key': None,
                 'exit': False}

    print("Configuring visualization ... ")
    graphics = setupVisualization(dataset, args, selection['collection_key'])

    # ---------------------------------------------
    # --- SUBSCRIBERS TO PLUGINS
    # ---------------------------------------------
    # ---------------------------------------
    # --- lidar3d modality
    # ---------------------------------------

    # Define subscriber to receive the selected points
    rospy.Subscriber("/rviz_selected_points", PointCloud2,
                     partial(selected_points_callback, selection=selection, dataset=dataset), queue_size=1,
                     buff_size=52428800)
    rospy.Subscriber("/rviz_selected_border_points", PointCloud2,
                     partial(selected_points_border_callback, selection=selection, dataset=dataset), queue_size=1,
                     buff_size=52428800)
    rospy.Subscriber("/rviz_selected_remove_points", PointCloud2,
                     partial(selected_points_remove_callback, selection=selection, dataset=dataset), queue_size=1,
                     buff_size=52428800)

    rospy.Subscriber("/rviz_selected_clear_all_points", PointCloud2,
                     partial(selected_points_clear_all_callback, selection=selection, dataset=dataset), queue_size=1,
                     buff_size=52428800)

    # ---------------------------------------
    # --- Depth modality
    # ---------------------------------------

    # Subscriber for the image_click plugin
    # this stores the pixel coordinates of clicked points per collection, and per sensor key
    clicked_points = {
        collection_key: {} for collection_key in dataset['collections']}

    # Initialize clicked points for all collections and sensors
    for collection_key in dataset['collections']:
        for sensor_key, sensor in dataset['sensors'].items():
            if sensor['modality'] == 'depth':
                clickedPointsReset(clicked_points, collection_key, sensor_key)

    # Create a subscriber for each depth sensor
    for sensor_key, sensor in dataset['sensors'].items():
        if sensor['modality'] == 'depth':
            points_topic = dataset['sensors'][sensor_key]['topic'] + \
                '/labeled/mouse_click'
            rospy.Subscriber(points_topic, PointStamped,
                             partial(clickedPointsCallback, clicked_points=clicked_points,
                                     dataset=dataset, sensor_key=sensor_key, selection=selection))

    # ---------------------------------------
    # --- Define callback to change idx_collection
    # ---------------------------------------
    key_pressed_partial = partial(
        keyPressed, selection=selection, dataset=dataset, args=args)
    listener = keyboard.Listener(
        on_press=key_pressed_partial)
    listener.start()

    rate = rospy.Rate(30)  # 30hz
    while not rospy.is_shutdown() and not selection['exit']:
        models = {'dataset': dataset, 'args': args, 'graphics': graphics}
        visualizationFunction(
            models=models, selection=selection, clicked_points=clicked_points)
        rate.sleep()


if __name__ == "__main__":
    main()
