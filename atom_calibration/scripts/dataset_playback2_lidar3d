#!/usr/bin/env python3
"""
casts an optimization problem using an atom dataset file as input. Then calibrates by running the optimization.
"""
import copy
import json
import os, math, signal, sys
import argparse, random
from functools import partial
import numpy as np
import ros_numpy
from pynput import keyboard
from sensor_msgs.msg import PointCloud2
import sensor_msgs.point_cloud2 as pc2


# 3rd-party
import rospy, tf
from colorama import Fore, Style, Back
from urdf_parser_py.urdf import URDF
from sensor_msgs.msg import PointCloud2
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import Point, Pose, Vector3, Quaternion, Transform, TransformStamped
from std_msgs.msg import Header, ColorRGBA

# own packages
import OptimizationUtils.OptimizationUtils as OptimizationUtils
import atom_core.naming
from atom_calibration.calibration.getters_and_setters import getterTransform, setterTransform, getterCameraIntrinsics, \
    setterCameraIntrinsics

from atom_core.naming import generateKey, generateName
from atom_core.utilities import waitForKeyPress, waitForKeyPress2
from atom_calibration.calibration.objective_function import getPointsInSensorAsNPArray, objectiveFunction
import atom_calibration.calibration.patterns_config as patterns
from atom_calibration.dataset_playback.visualization_lidar3d import setupVisualization, visualizationFunction
from atom_core.config_io import readXacroFile, uriReader
from atom_core.dataset_io import loadResultsJSON, saveResultsJSON, \
    getPointCloudMessageFromDictionary, filterCollectionsFromDataset, filterSensorsFromDataset, \
    addNoiseToInitialGuess
from atom_core.dataset_io import getPointCloudMessageFromDictionary, genCollectionPrefix


# global variavels

# var to select the index of the collection we want to see
global idx_collection
previous_selected_collection_key = None

# -------------------------------------------------------------------------------
# --- FUNCTIONS
# -------------------------------------------------------------------------------

def selected_points_callback(selected_point_cloud, listener1, models):
    global idx_collection
    selected_collection_key = list(models['dataset']['collections'].keys())[idx_collection]
    
    # Extract xyz coordinates from the selected points
    xyz_selected = []
    points_selected = pc2.read_points(selected_point_cloud, skip_nans=True)
    gen_points = list(points_selected)
    print('point_in', selected_collection_key)
    for point in gen_points:
        xyz_selected.append([point[0],point[1],point[2], 1])
        
    # Extract xyz coordinates from the original point cloud
    original_point_cloud = getPointCloudMessageFromDictionary(models['dataset']['collections'][selected_collection_key]['data']['lidar3d'])
    xyz_original = []
    points_original = pc2.read_points(original_point_cloud, skip_nans=True)
    gen_points = list(points_original)
    for point in gen_points:
        xyz_original.append([point[0],point[1],point[2], 1])
        
    
    # Get transformation to transform the frame of the original pointcloud (lidar3d) into the frame of the selected points (base_footprint)
    
    prefix='c' + selected_collection_key + '_'
    while not rospy.is_shutdown():
        try:
            listener1.waitForTransform(selected_point_cloud.header.frame_id, prefix + original_point_cloud.header.frame_id,rospy.Time(), rospy.Duration(1.0))
            (trans, quat) = listener1.lookupTransform(selected_point_cloud.header.frame_id, prefix + original_point_cloud.header.frame_id, rospy.Time())
            break
        except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException):
            continue
    # Compute 3D tranlaction matrix (ignoring quat beacuse we are dealing with points)
    trans_matrix = np.zeros((4,4))
    trans_matrix[:3,3] = trans
    trans_matrix[0,0] = 1
    trans_matrix[1,1] = 1
    trans_matrix[2,2] = 1
    trans_matrix[3,3] = 1
    
    
    xyz_original_corrected = []
    for point in xyz_original:
        xyz_original_corrected.append(np.dot(trans_matrix, np.array(point).reshape((4,1))).reshape(1,4)[0].tolist())
                    
    # Find idxs of the selected points!
    idxs = []
    for selected_point in xyz_selected:
        idxs_distance = []
        for original_corrected in xyz_original_corrected:
            idxs_distance.append(np.linalg.norm(np.subtract(selected_point, original_corrected)))
        idxs.append(idxs_distance.index(min(idxs_distance)))
        
            
    # update dataset with new indexs!
    models['dataset']['collections'][selected_collection_key]['labels']['lidar3d']['idxs'] = idxs
    
    
    
    # # add only the other collections!!
    
    
    # marker_array = MarkerArray()
    # marker_array_new = MarkerArray()
    
    # for marker in models['graphics']['ros']['MarkersLabeled'].markers:
    #     prefix = marker.header.frame_id[:3]
    #     if prefix == 'c' + str(selected_collection_key) + '_':
    #         marker_array.markers.append(marker)
    #         marker_array.markers[-1].action = Marker.DELETE
    #     else:
    #         marker_array_new.markers.append(marker)
    #         marker_array_new.markers[-1].action = Marker.ADD
            
            
    # models['graphics']['ros']['PubLabeled'].publish(marker_array)
    # models['graphics']['ros']['PubLabeled'].publish(marker_array_new)
            
            
               
    # frame_id = genCollectionPrefix(selected_collection_key, models['dataset']['collections'][selected_collection_key]['data']['lidar3d']['header']['frame_id'])
    # marker = Marker(header=Header(frame_id=frame_id, stamp=rospy.Time.now()),
    #                 ns=str(selected_collection_key) + '-' + str('lidar3d'), id=0, frame_locked=True,
    #                 type=Marker.SPHERE_LIST, action=Marker.ADD, lifetime=rospy.Duration(0),
    #                 pose=Pose(position=Point(x=0, y=0, z=0), orientation=Quaternion(x=0, y=0, z=0, w=1)),
    #                 scale=Vector3(x=0.05, y=0.05, z=0.05),
    #                 color=ColorRGBA(r=models['graphics']['collections'][selected_collection_key]['color'][0],
    #                                 g=models['graphics']['collections'][selected_collection_key]['color'][1],
    #                                 b=models['graphics']['collections'][selected_collection_key]['color'][2], a=0.5)
    #                 )

    # points = getPointsInSensorAsNPArray(selected_collection_key, 'lidar3d', 'idxs', models['dataset'])

    # for idx in range(0, points.shape[1]):
    #     marker.points.append(Point(x=points[0, idx], y=points[1, idx], z=points[2, idx]))

    # marker_array_new.markers.append(copy.deepcopy(marker))

    
            
    # # append new markers (related with the current collection)
    # models['graphics']['ros']['MarkersLabeled'] = marker_array_new
            
    



def signal_handler(sig, frame, dataset, args):
    print('Stopping optimization (Ctrl+C pressed)')
    # Save new dataset to json file
    
    D = {'sensors': dataset['sensors'], 'additional_sensor_data': dataset['additional_sensor_data'],
            'collections': dataset['collections'], 'calibration_config': dataset['calibration_config']}
    
   
    output_file =  '/'.join(args['json_file'].split('/')[:-1]) + '/dataset_corrected.json'
    atom_core.dataset_io.saveResultsJSON(output_file, D)
    sys.exit(0)

# function to enable change collection in RViz through the keys
def key_pressed(key, idx_max_collection, collections_list):
    global idx_collection
    global previous_selected_collection_key

    if key == keyboard.Key.right:
        if idx_collection < idx_max_collection:
            previous_selected_collection_key = collections_list[idx_collection]
            idx_collection += 1
            print('changed selected_collection_key to ' + str(collections_list[idx_collection]))
        else:
            print(Fore.RED + 'This is the last collection!!' + Fore.RESET)
    if key == keyboard.Key.left:
        if idx_collection > 0:
            previous_selected_collection_key = collections_list[idx_collection]
            idx_collection -= 1
            print('changed selected_collection_key to ' + str(collections_list[idx_collection]))
        else:
            print(Fore.RED + 'This is the first collection!!' + Fore.RESET)


# -------------------------------------------------------------------------------
# --- MAIN
# -------------------------------------------------------------------------------
def main():

    # var to select the index of the collection we want to see
    global idx_collection
    global previous_selected_collection_key

    # ---------------------------------------
    # --- Parse command line argument
    # ---------------------------------------

    
    # print('Press Ctrl+C')
    # signal.pause()

    ap = argparse.ArgumentParser()
    ap = OptimizationUtils.addArguments(ap)  # OptimizationUtils arguments
    ap.add_argument("-json", "--json_file", help="Json file containing input dataset.", type=str, required=True)
    ap.add_argument("-v", "--verbose", help="Be verbose", action='store_true', default=False)
    ap.add_argument("-rv", "--ros_visualization", help="Publish ros visualization markers.", action='store_true')
    ap.add_argument("-si", "--show_images", help="shows images for each camera", action='store_true', default=False)
    ap.add_argument("-oi", "--optimize_intrinsics", help="Adds camera instrinsics to the optimization",
                    action='store_true', default=False)
    ap.add_argument("-pof", "--profile_objective_function",
                    help="Runs and prints a profile of the objective function, then exits.",
                    action='store_true', default=False)
    ap.add_argument("-sr", "--sample_residuals", help="Samples residuals", type=float, default=1)
    ap.add_argument("-ss", "--sample_seed", help="Sampling seed", type=int)
    ap.add_argument("-ajf", "--all_joints_fixed",
                    help="Assume all joints are fixed and because of that draw a single robot mesh. Overrides "
                         "automatic detection of static robot.",
                    action='store_true', default=False)
    ap.add_argument("-uic", "--use_incomplete_collections",
                    help="Remove any collection which does not have a detection for all sensors.",
                    action='store_true', default=False)
    ap.add_argument("-rpd", "--remove_partial_detections",
                    help="Remove detected labels which are only partial. Used or the Charuco.",
                    action='store_true', default=False)
    ap.add_argument("-nig", "--noisy_initial_guess", nargs=2, metavar=('translation', 'rotation'),
                    help="Percentage of noise to add to the initial guess atomic transformations set before.",
                    type=float, default=[0.0, 0.0]),
    ap.add_argument("-ssf", "--sensor_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a sensor name as input and '
                         'returns True or False to indicate if the sensor should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: name in ["left_laser", "frontal_camera"] , to load only '
                         'sensors left_laser and frontal_camera')
    ap.add_argument("-csf", "--collection_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a collection name as input and '
                         'returns True or False to indicate if the collection should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: int(name) > 5 , to load only collections 6, 7, and onward.')
    ap.add_argument("-phased", "--phased_execution", help="Stay in a loop before calling optimization, and in another "
                                                          "after calling the optimization. Good for debugging.",
                    action='store_true', default=False)
    ap.add_argument("-ipg", "--initial_pose_ghost",
                    help="Draw a ghost mesh with the systems initial pose. Good for debugging.",
                    action='store_true', default=False)
    ap.add_argument('-oj', '--output_json', help='Full path to output json file.', type=str, required=False,
                    default=None)
    ap.add_argument('-ox', '--output_xacro', help='Full path to output xacro file.', type=str, required=False,
                    default=None)

    # Roslaunch adds two arguments (__name and __log) that break our parser. Lets remove those.
    arglist = [x for x in sys.argv[1:] if not x.startswith('__')]
    args = vars(ap.parse_args(args=arglist))



    # ---------------------------------------
    # --- INITIALIZATION Read data from file
    # ---------------------------------------
    
    # Loads a json file containing the detections. Returned json_file has path resolved by urireader.
    dataset, json_file = loadResultsJSON(args['json_file'], args['collection_selection_function'])

    # ---------------------------------------
    # --- Filter some collections and / or sensors from the dataset
    # ---------------------------------------
    dataset = filterCollectionsFromDataset(dataset, args)  # filter collections

    # Create the chessboard dataset must be called before deleting the sensors to cope with the possibility of
    # setting up an optimization without cameras. For now we MUST have a camera to estimate the initial parameters
    # related to the pattern pose (we use solve PNP for a camera).
    dataset['patterns'] = patterns.createPatternLabels(args, dataset)  # TODO: Solve this strange dependency.

    dataset = filterSensorsFromDataset(dataset, args)  # filter sensors

    print('Loaded dataset containing ' + str(len(dataset['sensors'].keys())) + ' sensors and ' + str(
        len(dataset['collections'].keys())) + ' collections.')
    
    # Create Ctl+c handler
    signal_handler_partial = partial(signal_handler, dataset = dataset, args=args)
    signal.signal(signal.SIGINT, signal_handler_partial)

    # ---------------------------------------
    # --- Store initial values for transformations to be optimized
    # ---------------------------------------
    for collection_key, collection in dataset['collections'].items():
        initial_transform_key = generateName('transforms', suffix='ini')
        collection[initial_transform_key] = copy.deepcopy(collection['transforms'])
        for transform_key, transform in collection[initial_transform_key].items():
            transform['parent'] = generateName(transform['parent'], suffix='ini')
            transform['child'] = generateName(transform['child'], suffix='ini')

    # ---------------------------------------
    # --- Define selected collection key.
    # ---------------------------------------
    # For the getters we only need to get one collection. Lets take the first key on the dictionary and always get that
    # transformation.
    idx_collection = 0
    collections_list = list(dataset['collections'].keys())
    selected_collection_key = collections_list[idx_collection]
    print('Selected collection key is ' + str(selected_collection_key))

    # ---------------------------------------
    # --- Define callback to change idx_collection
    # ---------------------------------------
    key_pressed_partial = partial(key_pressed, idx_max_collection = len(collections_list) - 1, collections_list = collections_list)
    listener = keyboard.Listener(
    on_press=key_pressed_partial)
    listener.start()
    
    # ---------------------------------------
    # --- SETUP OPTIMIZER: Create data models
    # ---------------------------------------
    opt = OptimizationUtils.Optimizer()
    opt.addDataModel('args', args)
    opt.addDataModel('dataset', dataset)

    # ---------------------------------------
    # --- SETUP OPTIMIZER: Add pattern(s) parameters
    # ---------------------------------------
    # Each Pattern will have the position (tx,ty,tz) and rotation (r1,r2,r3)

    if not dataset['calibration_config']['calibration_pattern']['fixed']:  # Pattern not fixed -------------------------
        # If pattern is not fixed there will be a transform for each collection. To tackle this reference link called
        # according to what is on the dataset['calibration_config']['calibration_pattern']['link'] is prepended with
        # a "c<collection_name>" appendix. This is done automatically for the collection['transforms'] when
        # publishing ROS, but we must add this to the parameter name.
        parent = dataset['calibration_config']['calibration_pattern']['parent_link']
        child = dataset['calibration_config']['calibration_pattern']['link']
        transform_key = atom_core.naming.generateKey(parent, child)

        for collection_key, collection in dataset['collections'].items():  # iterate all collections

            # Set transform using the initial estimate of the transformations.
            initial_estimate = dataset['patterns']['transforms_initial'][collection_key]
            if not initial_estimate['detected'] or not parent == initial_estimate['parent'] or \
                    not child == initial_estimate['child']:
                raise ValueError('Cannot set initial estimate for pattern at collection ' + collection_key)

            collection['transforms'][transform_key] = {'parent': parent, 'child': child,
                                                       'trans': initial_estimate['trans'],
                                                       'quat': initial_estimate['quat']}

    else:  # fixed pattern ---------------------------------------------------------------------------------------------
        # if pattern is fixed it will not be replicated for all collections , i.e. there will be a single
        # reference link called according to what is on the dataset['calibration_config']['calibration_pattern'][
        # 'link']
        parent = dataset['calibration_config']['calibration_pattern']['parent_link']
        child = dataset['calibration_config']['calibration_pattern']['link']
        transform_key = atom_core.naming.generateKey(parent, child)

        # Set transform using the initial estimate of the transformations.
        initial_estimate = dataset['patterns']['transforms_initial'][selected_collection_key]
        if not initial_estimate['detected'] or not parent == initial_estimate['parent'] or \
                not child == initial_estimate['child']:
            raise ValueError('Cannot set initial estimate for pattern at collection ' + collection_key)

        # The pattern is fixed but we have a replicated transform for each collection. Lets add those.
        for collection_key, collection in dataset['collections'].items():
            collection['transforms'][transform_key] = {'parent': parent, 'child': child,
                                                       'trans': initial_estimate['trans'],
                                                       'quat': initial_estimate['quat']}

    # ---------------------------------------
    # --- DEFINE THE VISUALIZATION FUNCTION
    # ---------------------------------------

    print("Configuring visualization ... ")
    graphics = setupVisualization(dataset, args, selected_collection_key)
    opt.addDataModel('graphics', graphics)
    
    
    # Define subscriber to receive the selected points
    listener1 = tf.TransformListener()
    selected_points_callback_partial = partial(selected_points_callback, listener1=listener1, models= opt.data_models)
    rospy.Subscriber("/rviz_selected_points", PointCloud2, selected_points_callback_partial, queue_size=1, buff_size=52428800) 
    
    rate = rospy.Rate(1)  # 10hz
    while not rospy.is_shutdown():
        selected_collection_key = collections_list[idx_collection]
        visualizationFunction(opt.data_models, selected_collection_key, previous_selected_collection_key)
        
        
        rate.sleep()


if __name__ == "__main__":
    main()
