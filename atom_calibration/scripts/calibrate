#!/usr/bin/env python
"""
Reads a set of data and labels from a group of sensors in a json file and calibrates the poses of these sensors.
"""

# stdlib
import os

import atom_core.atom
import atom_core.naming
import signal
import sys
import argparse
from functools import partial

from urdf_parser_py.urdf import URDF

# 3rd-party
import rospy
import tf
import cv2
import numpy as np
from colorama import Fore, Style, Back

import OptimizationUtils.OptimizationUtils as OptimizationUtils

# own packages
import atom_calibration.calibration.getters_and_setters as getters_and_setters
import atom_calibration.calibration.objective_function as objective_function
import atom_calibration.calibration.patterns_config as patterns
import atom_calibration.calibration.visualization as visualization
from atom_core.config_io import readXacroFile, uriReader
from atom_core.dataset_io import loadResultsJSON, saveResultsJSON, getCvImageFromDictionary, \
    getPointCloudMessageFromDictionary, filterCollectionsFromDataset


# -------------------------------------------------------------------------------
# --- FUNCTIONS
# -------------------------------------------------------------------------------
def signal_handler(sig, frame):
    print('Stopping optimization (Ctrl+C pressed)')
    sys.exit(0)


# -------------------------------------------------------------------------------
# --- MAIN
# -------------------------------------------------------------------------------
def main():
    # ---------------------------------------
    # --- Parse command line argument
    # ---------------------------------------
    signal.signal(signal.SIGINT, signal_handler)
    # print('Press Ctrl+C')
    # signal.pause()

    ap = argparse.ArgumentParser()
    ap = OptimizationUtils.addArguments(ap)  # OptimizationUtils arguments
    ap.add_argument("-json", "--json_file", help="Json file containing input dataset.", type=str, required=True)
    ap.add_argument("-rv", "--ros_visualization", help="Publish ros visualization markers.", action='store_true')
    ap.add_argument("-si", "--show_images", help="shows images for each camera", action='store_true', default=False)
    ap.add_argument("-oi", "--optimize_intrinsics", help="Adds camera instrinsics to the optimization",
                    action='store_true', default=False)
    ap.add_argument("-pof", "--profile_objective_function",
                    help="Runs and prints a profile of the objective function, then exits.",
                    action='store_true', default=False)
    ap.add_argument("-sr", "--sample_residuals", help="Samples residuals", type=float, default=1)
    ap.add_argument("-od", "--optimize_distortion", help="Adds camera distortion parameters to the optimization",
                    action='store_true', default=False)
    ap.add_argument("-fec", "--four_extrema_corners", help="Uses only the four extrema corners for camera "
                                                           "optimizations, i.e. top left and right, bottom left and "
                                                           "right. This speeds up the optimization procedure (since "
                                                           "the number of residuals greatly reduces) but may result "
                                                           "in a less accurate calibration",
                    action='store_true', default=False)
    ap.add_argument("-uic", "--use_incomplete_collections",
                    help="Remove any collection which does not have a detection for all sensors.",
                    action='store_true', default=False)
    ap.add_argument("-rpd", "--remove_partial_detections",
                    help="Remove detected labels which are only partial. Used or the Charuco.",
                    action='store_true', default=False)
    ap.add_argument("-ssf", "--sensor_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a sensor name as input and '
                         'returns True or False to indicate if the sensor should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: name in ["left_laser", "frontal_camera"] , to load only '
                         'sensors left_laser and frontal_camera')
    ap.add_argument("-csf", "--collection_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a collection name as input and '
                         'returns True or False to indicate if the collection should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: int(name) > 5 , to load only collections 6, 7, and onward.')

    # Filter unwanted arguments.
    # Roslaunch adds two arguments (__name and __log) that break our parser
    arglist = [x for x in sys.argv[1:] if not x.startswith('__')]
    args = vars(ap.parse_args(args=arglist))

    # ---------------------------------------
    # --- INITIALIZATION Read data from file
    # ---------------------------------------

    # Loads a json file containing the detections. Returned json_file has path resolved by urireader.
    dataset, json_file = loadResultsJSON(args['json_file'])

    # Refine detection labels
    # TODO Must this really be here? It should go into data collector, right?
    for collection_key, collection in dataset['collections'].items():
        for sensor_key, sensor in dataset['sensors'].items():
            if sensor['msg_type'] == 'Image':  # Load image.

                if not collection['labels'][sensor_key]['detected']:
                    continue

                # we need and opencv image, but the json stores the dictionary converted from a ros message.
                # Must convert back to opencv image.
                cv_image = getCvImageFromDictionary(collection['data'][sensor_key])
                gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

                nc = len(collection['labels'][sensor_key]['idxs'])
                corners = []
                for idxs in collection['labels'][sensor_key]['idxs']:
                    corners.append(np.array([[idxs['x'], idxs['y']]]))

                corners = np.array(corners, dtype=np.float32)
                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 500, 0.0001)
                corners = cv2.cornerSubPix(gray, corners, (3, 3), (-1, -1), criteria)

                for id, corner in enumerate(collection['labels'][sensor_key]['idxs']):
                    corner['x'] = float(corners[id][0][0])
                    corner['y'] = float(corners[id][0][1])

    # Remove unwanted collections
    dataset = filterCollectionsFromDataset(dataset, args)


    # ---------------------------------------
    # --- CREATE CHESSBOARD DATASET
    # ---------------------------------------
    dataset['patterns'] = patterns.createPatternLabels(args, dataset)

    # ---------------------------------------
    # --- FILTER SOME OF THE ELEMENTS LOADED, TO USE ONLY A SUBSET IN THE CALIBRATION
    # ---------------------------------------
    if not args['sensor_selection_function'] is None:
        deleted = []
        for sensor_key in dataset['sensors'].keys():
            if not args['sensor_selection_function'](sensor_key):  # use the lambda expression ssf
                deleted.append(sensor_key)
                del dataset['sensors'][sensor_key]
        print("Deleted sensors: " + str(deleted))

    print('Loaded dataset containing ' + str(len(dataset['sensors'].keys())) + ' sensors and ' + str(
        len(dataset['collections'].keys())) + ' collections.')

    # ---------------------------------------
    # --- DETECT EDGES IN THE LASER SCANS
    # ---------------------------------------
    for sensor_key, sensor in dataset['sensors'].items():
        if sensor['msg_type'] == 'LaserScan':  # only for lasers
            for collection_key, collection in dataset['collections'].items():
                idxs = collection['labels'][sensor_key]['idxs']
                edges = []  # a list of edges
                for i in range(0, len(idxs) - 1):
                    if (idxs[i + 1] - idxs[i]) != 1:
                        edges.append(i)
                        edges.append(i + 1)

                # Remove first (right most) and last (left most) edges, since these are often false edges.
                if len(edges) > 0:
                    edges.pop(0)  # remove the first element.
                if len(edges) > 0:
                    edges.pop()  # if the index is not given, then the last element is popped out and removed.
                collection['labels'][sensor_key]['edge_idxs'] = edges

    # ---------------------------------------
    # --- Detect corners in velodyne data
    # ---------------------------------------
    for sensor_key, sensor in dataset['sensors'].items():
        if sensor['msg_type'] == 'PointCloud2':  # only for 3D Lidars and RGBD cameras
            for collection_key, collection in dataset['collections'].items():
                import ros_numpy
                cloud_msg = getPointCloudMessageFromDictionary(collection['data'][sensor_key])

                # ------------------------------------------------------------------------------------------------
                # -------- Extract the labelled LiDAR points on the pattern
                # ------------------------------------------------------------------------------------------------
                idxs = collection['labels'][sensor_key]['idxs']
                pc = ros_numpy.numpify(cloud_msg)[idxs]
                points = np.zeros((pc.shape[0], 4))
                points[:, 0] = pc['x']
                points[:, 1] = pc['y']
                points[:, 2] = pc['z']
                points[:, 3] = 1
                collection['labels'][sensor_key]['labelled_points'] = []
                for idx in range(0, points.shape[0]):
                    collection['labels'][sensor_key]['labelled_points'].append(
                        {'x': points[idx, 0], 'y': points[idx, 1], 'z': points[idx, 2],
                         'w': points[idx, 3]})

                # - Cartesian to polar LiDAR points conversion
                import math
                points_sph = []
                for idx in range(points.shape[0]):
                    m_pt = points[idx, 0:3]
                    r = math.sqrt(m_pt[0] ** 2 + m_pt[1] ** 2 + m_pt[2] ** 2)
                    theta = math.acos(m_pt[2] / r)
                    phi = math.atan2(m_pt[1], m_pt[0])

                    m_pt_shp = [r, theta, phi]
                    points_sph.append(m_pt_shp)

                # - LiDAR beam clustering using the theta component
                points_sph = np.array(points_sph).transpose()
                thetas = points_sph[1, :].round(decimals=4)  # we round so that we can use the np.unique
                unique, indexes, inverse_indexes = np.unique(thetas, return_index=True, return_inverse=True)

                # - Find the extrema points using the maximum and minimum of the phi component for each cluster
                extrema_points = []
                middle_points = []
                for i in range(0, len(indexes)):
                    m_beam = np.where(inverse_indexes == i)

                    phis = points_sph[2, m_beam][0]
                    min_idx = np.argmin(phis)
                    max_idx = np.argmax(phis)

                    for phi in phis:
                        if not phi == np.min(phis) and not phi == np.max(phis):
                            idx = np.where(points_sph[2, :] == phi)[0][0]
                            middle_points.append(points[idx, :])

                    global_min_idx = np.where(points_sph[2, :] == phis[min_idx])[0][0]
                    global_max_idx = np.where(points_sph[2, :] == phis[max_idx])[0][0]

                    extrema_points.append(points[global_min_idx, :])
                    extrema_points.append(points[global_max_idx, :])

                # Save extrema points in a dictionary
                collection['labels'][sensor_key]['limit_points'] = []
                extrema_points = np.array(extrema_points)
                for idx in range(0, len(extrema_points)):
                    collection['labels'][sensor_key]['limit_points'].append(
                        {'x': extrema_points[idx, 0], 'y': extrema_points[idx, 1], 'z': extrema_points[idx, 2],
                         'w': extrema_points[idx, 3]})
                collection['labels'][sensor_key]['middle_points'] = []
                middle_points = np.array(middle_points)
                for idx in range(0, len(middle_points)):
                    collection['labels'][sensor_key]['middle_points'].append(
                        {'x': middle_points[idx, 0], 'y': middle_points[idx, 1], 'z': middle_points[idx, 2],
                         'w': middle_points[idx, 3]})

    # ---------------------------------------
    # --- SETUP OPTIMIZER: Create data models
    # ---------------------------------------
    opt = OptimizationUtils.Optimizer()
    opt.addDataModel('args', args)
    opt.addDataModel('dataset', dataset)

    # For the getters we only need to get one collection. Lets take the first key on the dictionary and always get that
    # transformation.
    selected_collection_key = dataset['collections'].keys()[0]

    # ---------------------------------------
    # --- DEFINE THE VISUALIZATION FUNCTION
    # ---------------------------------------
    if args['view_optimization']:
        opt.setInternalVisualization(True)
    else:
        opt.setInternalVisualization(False)

    if args['ros_visualization']:
        print("Configuring visualization ... ")
        graphics = visualization.setupVisualization(dataset, args, selected_collection_key)
        opt.addDataModel('graphics', graphics)

        opt.setVisualizationFunction(visualization.visualizationFunction, args['ros_visualization'], niterations=1,
                                     figures=[])


    # ---------------------------------------
    # --- SETUP OPTIMIZER: Add sensor parameters
    # ---------------------------------------
    # Each sensor will have a position (tx,ty,tz) and a rotation (r1,r2,r3)

    # Add parameters related to the sensors
    translation_delta = 0.2
    # TODO temporary placement of top_left_camera
    # for collection_key, collection in dataset['collections'].items():
    #     collection['transforms']['base_link-top_left_camera']['trans'] = [-1.48, 0.22, 1.35]
    # dataset['calibration_config']['anchored_sensor'] = 'left_camera'
    print('Anchored sensor is ' + Fore.GREEN + dataset['calibration_config'][
        'anchored_sensor'] + Style.RESET_ALL)

    anchored_sensor = dataset['calibration_config']['anchored_sensor']
    if anchored_sensor in dataset['sensors']:
        anchored_parent = dataset['sensors'][anchored_sensor]['calibration_parent']
        anchored_child = dataset['sensors'][anchored_sensor]['calibration_child']
        anchored_transform_key = atom_core.naming.generateKey(anchored_parent, anchored_child)
    else:
        anchored_transform_key = ''  # not transform is anchored
    # TODO If we want and anchored sensor we should search (and fix) all the transforms in its chain that do are being optimized

    print('Creating parameters ...')
    # Steaming from the config json, we define a transform to be optimized for each sensor. It could happen that two
    # or more sensors define the same transform to be optimized (#120). To cope with this we first create a list of
    # transformations to be optimized and then compute the unique set of that list.
    transforms_set = set()
    for sensor_key, sensor in dataset['sensors'].items():
        transform_key = atom_core.naming.generateKey(sensor['calibration_parent'], sensor['calibration_child'])
        transforms_set.add(transform_key)

    for transform_key in transforms_set:  # push six parameters for each transform to be optimized.
        initial_transform = getters_and_setters.getterTransform(dataset, transform_key=transform_key,
                                                                collection_name=collection_key)

        if transform_key == anchored_transform_key:
            bound_max = [x + sys.float_info.epsilon for x in initial_transform]
            bound_min = [x - sys.float_info.epsilon for x in initial_transform]
        else:
            bound_max = [+np.inf for x in initial_transform]
            bound_min = [-np.inf for x in initial_transform]

        opt.pushParamVector(group_name=transform_key, data_key='dataset',
                            getter=partial(getters_and_setters.getterTransform, transform_key=transform_key,
                                           collection_name=selected_collection_key),
                            setter=partial(getters_and_setters.setterTransform, transform_key=transform_key,
                                           collection_name=None),
                            suffix=['_x', '_y', '_z', '_r1', '_r2', '_r3'], bound_max=bound_max, bound_min=bound_min)

    # Intrinsics
    # TODO bound_min and max for intrinsics
    if args['optimize_intrinsics']:
        for sensor_key, sensor in dataset['sensors'].items():
            if sensor['msg_type'] == 'Image':  # if sensor is a camera add intrinsics
                opt.pushParamVector(group_name=str(sensor_key) + '_intrinsics', data_key='dataset',
                                    getter=partial(getters_and_setters.getterCameraIntrinsics, sensor_key=sensor_key),
                                    setter=partial(getters_and_setters.setterCameraIntrinsics, sensor_key=sensor_key),
                                    suffix=['_fx', '_fy', '_cx', '_cy', '_k1', '_k2', '_t1', '_t2', '_k3'])

    # TODO handle optimize_distortion

    # ---------------------------------------
    # --- SETUP OPTIMIZER: Add pattern(s) parameters
    # ---------------------------------------
    # Each Pattern will have the position (tx,ty,tz) and rotation (r1,r2,r3)

    if not dataset['calibration_config']['calibration_pattern']['fixed']:  # Pattern not fixed -------------------------
        # If pattern is not fixed there will be a transform for each collection. To tackle this reference link called
        # according to what is on the dataset['calibration_config']['calibration_pattern']['link'] is prepended with
        # a "c<collection_name>" appendix. This is done automatically for the collection['transforms'] when
        # publishing ROS, but we must add this to the parameter name.
        parent = dataset['calibration_config']['calibration_pattern']['parent_link']
        child = dataset['calibration_config']['calibration_pattern']['link']
        transform_key = atom_core.naming.generateKey(parent, child)

        for collection_key, collection in dataset['collections'].items():  # iterate all collections

            # Set transform using the initial estimate of the transformations.
            initial_estimate = dataset['patterns']['transforms_initial'][collection_key]
            if not initial_estimate['detected'] or not parent == initial_estimate['parent'] or \
                    not child == initial_estimate['child']:
                raise ValueError('Cannot set initial estimate for pattern at collection ' + collection_key)

            collection['transforms'][transform_key] = {'parent': parent, 'child': child,
                                                       'trans': initial_estimate['trans'],
                                                       'quat': initial_estimate['quat']}

            # Finally push the six parameters to describe the patterns pose w.r.t its parent link:
            #   a) The Getter will pick up transform from the collection collection_key
            #   b) The Setter will received a transform value and a collection_key and copy the transform to that of the
            #   corresponding collection
            opt.pushParamVector(group_name='c' + collection_key + '_' + transform_key, data_key='dataset',
                                getter=partial(getters_and_setters.getterTransform, transform_key=transform_key,
                                               collection_name=collection_key),
                                setter=partial(getters_and_setters.setterTransform, transform_key=transform_key,
                                               collection_name=collection_key),
                                suffix=['_x', '_y', '_z', '_r1', '_r2', '_r3'])

    else:  # fixed pattern ---------------------------------------------------------------------------------------------
        # if pattern is fixed it will not be replicated for all collections , i.e. there will be a single
        # reference link called according to what is on the dataset['calibration_config']['calibration_pattern'][
        # 'link']
        parent = dataset['calibration_config']['calibration_pattern']['parent_link']
        child = dataset['calibration_config']['calibration_pattern']['link']
        transform_key = atom_core.naming.generateKey(parent, child)

        # Set transform using the initial estimate of the transformations.
        initial_estimate = dataset['patterns']['transforms_initial'][collection_key]
        if not initial_estimate['detected'] or not parent == initial_estimate['parent'] or \
                not child == initial_estimate['child']:
            raise ValueError('Cannot set initial estimate for pattern at collection ' + collection_key)

        # The pattern is fixed but we have a replicated transform for each collection. Lets add those.
        for collection_key, collection in dataset['collections'].items():
            collection['transforms'][transform_key] = {'parent': parent, 'child': child,
                                                       'trans': initial_estimate['trans'],
                                                       'quat': initial_estimate['quat']}

        # Finally push the six parameters to describe the patterns pose w.r.t its parent link:
        #   a) The Getter will pick up the collection from one selected collection (it does not really matter which,
        #       since they are replicas);
        #   b) The Setter will received a transform value and copy that to all collection replicas, to ensure they
        #       all have the same value. This is done by setting  "collection_name=None".
        opt.pushParamVector(group_name=transform_key, data_key='dataset',
                            getter=partial(getters_and_setters.getterTransform, transform_key=transform_key,
                                           collection_name=selected_collection_key),
                            setter=partial(getters_and_setters.setterTransform, transform_key=transform_key,
                                           collection_name=None),
                            suffix=['_x', '_y', '_z', '_r1', '_r2', '_r3'])

    # opt.printParameters()

    # ---------------------------------------
    # --- Define THE OBJECTIVE FUNCTION
    # ---------------------------------------
    opt.setObjectiveFunction(objective_function.objectiveFunction)

    # ---------------------------------------
    # --- Define THE RESIDUALS
    # ---------------------------------------
    # Each residual is computed after the sensor and the pattern of a collection. Thus, each error will be affected
    # by the parameters tx,ty,tz,r1,r2,r3 of the sensor and the pattern

    print("Creating residuals ... ")
    for collection_key, collection in dataset['collections'].items():
        for sensor_key, sensor in dataset['sensors'].items():
            if not collection['labels'][sensor_key]['detected']:  # if pattern not detected by sensor in collection
                continue

            # Sensor related parameters
            sensors_transform_key = atom_core.naming.generateKey(sensor['calibration_parent'],
                                                                 sensor['calibration_child'])
            params = opt.getParamsContainingPattern(sensors_transform_key)

            # Intrinsics parameters
            if sensor['msg_type'] == 'Image' and args['optimize_intrinsics']:
                params.extend(opt.getParamsContainingPattern(sensor_key + '_intrinsics'))

            # Pattern related parameters
            if dataset['calibration_config']['calibration_pattern']['fixed']:
                pattern_transform_key = atom_core.naming.generateKey(
                    dataset['calibration_config']['calibration_pattern']['parent_link'],
                    dataset['calibration_config']['calibration_pattern']['link'])
            else:
                pattern_transform_key = 'c' + collection_key + '_' + atom_core.naming.generateKey(
                    dataset['calibration_config']['calibration_pattern']['parent_link'],
                    dataset['calibration_config']['calibration_pattern']['link'])

            params.extend(opt.getParamsContainingPattern(pattern_transform_key))  # pattern related params

            if sensor['msg_type'] == 'Image':  # if sensor is a camera use four residuals

                # Compute step as a function of residual sampling factor
                for idx in collection['labels'][sensor_key]['idxs']:  # using all pattern corners
                    rname = 'c' + str(collection_key) + '_' + str(sensor_key) + '_corner' + str(idx['id'])
                    opt.pushResidual(name=rname, params=params)

            elif sensor['msg_type'] == 'LaserScan':  # if sensor is a 2D lidar add two residuals
                # TODO Implement sampling here if relevant
                # Extrema points (longitudinal error)
                opt.pushResidual(name='c' + collection_key + '_' + sensor_key + '_eleft', params=params)
                opt.pushResidual(name='c' + collection_key + '_' + sensor_key + '_eright', params=params)

                # Inner points, use detection of edges (longitudinal error)
                for idx, _ in enumerate(collection['labels'][sensor_key]['edge_idxs']):
                    opt.pushResidual(name='c' + collection_key + '_' + sensor_key + '_inner_' + str(idx), params=params)

                # Laser beam (orthogonal error)
                for idx in range(0, len(collection['labels'][sensor_key]['idxs'])):
                    opt.pushResidual(name='c' + collection_key + '_' + sensor_key + '_beam_' + str(idx), params=params)

            elif sensor['msg_type'] == 'PointCloud2':  # if sensor is a 3D lidar add two types of residuals
                # Laser beam error
                step = int(1 / float(args['sample_residuals']))
                # for idx in range(0, len(collection['labels'][sensor_key]['middle_points']), step):
                for idx in range(0, len(collection['labels'][sensor_key]['idxs']), step):
                    opt.pushResidual(name='c' + collection_key + '_' + sensor_key + '_oe_' + str(idx), params=params)
                # Extrema displacement error
                for idx in range(0, len(collection['labels'][sensor_key]['limit_points'])):
                    opt.pushResidual(name='c' + collection_key + '_' + sensor_key + '_ld_' + str(idx), params=params)

            # print('Adding residuals for sensor ' + sensor_key + ' with msg_type ' + sensor['msg_type'] +
            #       ' affected by parameters:\n' + str(params))

    opt.printResiduals()

    # Get a normalizer for each residual type
    msg_types = set([s['msg_type'] for s in dataset['sensors'].values()])
    normalizer = {k: 1.0 for k in msg_types}
    opt.addDataModel('normalizer', normalizer)

    residuals = objective_function.objectiveFunction(opt.data_models)
    for msg_type in msg_types:
        values = []
        for sensor_key, sensor in dataset['sensors'].items():
            if sensor['msg_type'] == msg_type:
                values += [residuals[k] for k in residuals.keys() if sensor_key in k]

        normalizer[msg_type] = np.mean(values)
    #--

    # ---------------------------------------
    # --- Compute the SPARSE MATRIX
    # ---------------------------------------
    print("Computing sparse matrix ... ")
    opt.computeSparseMatrix()
    # opt.printSparseMatrix()

    # ---------------------------------------
    # --- Profile Objective Function
    # ---------------------------------------
    if args['profile_objective_function']:
        from line_profiler import LineProfiler
        lp1 = LineProfiler()
        lp_wrapper1 = lp1(objective_function.objectiveFunction)
        lp_wrapper1(opt.data_models)

        print(Back.LIGHTYELLOW_EX + '\n\n' + Fore.RED + Style.BRIGHT + 'First call of Objective Function (no cache)'
              + '\n\n' + Back.RESET + Fore.RESET + Style.RESET_ALL)
        lp1.print_stats()

        lp2 = LineProfiler()
        lp_wrapper2 = lp2(objective_function.objectiveFunction)
        lp_wrapper2(opt.data_models)
        print(Back.LIGHTYELLOW_EX + '\n\n' + Fore.RED + Style.BRIGHT + 'Second call of Objective Function (with cache)'
              + '\n\n' + Back.RESET + Fore.RESET + Style.RESET_ALL)
        lp2.print_stats()
        exit(0)

    # ---------------------------------------
    # --- Start Optimization
    # ---------------------------------------
    print('Initializing optimization ...')

    options = {'ftol': 1e-5, 'xtol': 1e-5, 'gtol': 1e-5, 'diff_step': None, 'x_scale': 'jac'}
    opt.startOptimization(optimization_options=options)

    # Error Report
    print('\nFinal errors:')
    r = objective_function.objectiveFunction(opt.data_models)
    for sensor_key, sensor in dataset['sensors'].items():
        keys = [ k for k in r.keys() if sensor_key in k]
        v = [ r[k] * normalizer[sensor['msg_type']]  for k in keys]
        print("Sensor " + sensor_key + " " + str(np.mean(v)))
    #--


    # ---------------------------------------
    # --- Save updated JSON file
    # ---------------------------------------
    filename_results_json = os.path.dirname(json_file) + '/atom_calibration.json'
    saveResultsJSON(filename_results_json, dataset)

    # ---------------------------------------
    # --- Save updated xacro
    # ---------------------------------------
    # Cycle all sensors in calibration config, and for each replace the optimized transform in the original xacro
    # Parse xacro description file
    description_file, _, _ = uriReader(dataset['calibration_config']['description_file'])
    rospy.loginfo('Reading description file ' + description_file + '...')
    xml_robot = readXacroFile(description_file)

    for sensor_key in dataset['calibration_config']['sensors']:
        child = dataset['calibration_config']['sensors'][sensor_key]['child_link']
        parent = dataset['calibration_config']['sensors'][sensor_key]['parent_link']
        transform_key = atom_core.naming.generateKey(parent, child)

        trans = list(dataset['collections'][selected_collection_key]['transforms'][transform_key]['trans'])
        quat = list(dataset['collections'][selected_collection_key]['transforms'][transform_key]['quat'])
        found = False

        for joint in xml_robot.joints:
            if joint.parent == parent and joint.child == child:
                found = True
                print('Found joint: ' + str(joint.name))

                print('Replacing xyz = ' + str(joint.origin.xyz) + ' by ' + str(trans))
                joint.origin.xyz = trans

                rpy = list(tf.transformations.euler_from_quaternion(quat, axes='sxyz'))
                print('Replacing rpy = ' + str(joint.origin.rpy) + ' by ' + str(rpy))
                joint.origin.rpy = rpy
                break

        if not found:
            raise ValueError('Could not find transform ' + str(transform_key) + ' in ' + description_file)

    # TODO find a way to find the <your_robot>_calibration path. For now write a xacro to /tmp
    # outfile = os.path.dirname(description_file) + '/optimized.urdf.xacro'
    outfile = '/tmp/optimized.urdf.xacro'
    with open(outfile, 'w') as out:
        out.write(URDF.to_xml_string(xml_robot))

    print('Optimized xacro file saved to ' + str(outfile) + ' . You can use it as a ROS robot_description.')


if __name__ == "__main__":
    main()
