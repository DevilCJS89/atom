#!/usr/bin/env python3

"""
Reads the calibration results from two json files and computes the evaluation metrics.

Get the values x,y,z,roll,pitch and yaw from transforms (values from calibrated URDF).
Get the values x,y,z,roll,pitch and yaw from the transforms_ini (values from original URDF).

Computes the different between them in millimeters and degrees.
e = |calibrated_frame - ground_truth_frame|

Get the transformation chain from the target_frame to the calibrated frame in the train json 
and in the test json and computes the average translation and rotation.

Notes: 
If no target frame were provided, the transformation chain starts on the first frame after the reference frame.
If no source frame were provided, computes the values to all estimated frames during the calibration process  
"""

# -------------------------------------------------------------------------------
# --- IMPORTS
# -------------------------------------------------------------------------------
# Standard imports
import argparse
import os
import math
import json
from collections import OrderedDict
from copy import deepcopy
import sys
from typing import List

# ROS imports
import cv2
import numpy as np
from matplotlib import cm
from colorama import Style, Fore
from prettytable import PrettyTable
from atom_core.geometry import matrixToRodrigues, traslationRodriguesToTransform

# Atom imports
from atom_core.atom import getTransform
from atom_core.utilities import rootMeanSquare, checkAdditionalTfs
from atom_core.naming import generateKey
from atom_core.drawing import drawCross2D, drawSquare2D

# -------------------------------------------------------------------------------
# --- OBJECTS 
# -------------------------------------------------------------------------------
class Table:
    def __init__(self, dict, arg) -> None:
        self.dict = dict
        self.header = ['frame #', 'Xcal-Xgt (mm)', 'Ycal-Ygt (mm)', 'Zcal-Zgt (mm)', 
                    'Roll_cal-Roll_gt (deg)', 'Pitch_cal-Pitch_gt (deg)', 'Yaw_cal-Yaw_gt (deg)', 
                    'Trans (mm)', 'Rot (deg)']
        self.table = PrettyTable(self.header)
        self.table_to_save = PrettyTable(self.header)
        self.arg = arg
        if arg != None: 
            self.save_to_csv = True
        else:
            self.save_to_csv = False

    def adding_rows(self) -> None:
        for frame_key, frame in self.dict.items():
            row = [frame_key, 
                '%.4f' % self.dict[frame_key]['x'],
                '%.4f' % self.dict[frame_key]['y'],
                '%.4f' % self.dict[frame_key]['z'],
                '%.4f' % self.dict[frame_key]['roll'],
                '%.4f' % self.dict[frame_key]['pitch'],
                '%.4f' % self.dict[frame_key]['yaw'],
                '%.4f' % self.dict[frame_key]['Trans'],
                '%.4f' % self.dict[frame_key]['Rot']
                ]
                   
            self.table.add_row(row)
            self.table_to_save.add_row(row)
    
    def table_to_csv(self) -> None:
        if self.save_to_csv:
            with open(self.arg + 'ground_truth_frame_results.csv', 'w', newline='') as f_output:
                f_output.write(self.table_to_save.get_csv_string())
    
    def print_table(self) -> None:
        self.adding_rows()
        self.table.align ='c'
        self.table_to_save.align ='c'
        print(Style.BRIGHT + 'Errors per frame' + Style.RESET_ALL)
        print(self.table)
        self.table_to_csv()

class FinalDictionary:
    def __init__(self, train_dataset, test_dataset, transform_key, target_frame, source_frame, source_child, dict) -> None:
        self.train_dataset = train_dataset
        self.test_dataset = test_dataset
        self.transform_key = transform_key
        self.target_frame = target_frame
        self.source_frame = source_frame
        self.source_child = source_child
        self.dict = dict

    def getCalibratedFrames(self) -> None:
        self.frame_calibrated_trans = self.train_dataset['collections'][list(self.train_dataset['collections'].keys())[0]]['transforms'][self.transform_key]['trans']
        self.frame_calibrated_quat = self.train_dataset['collections'][list(self.train_dataset['collections'].keys())[0]]['transforms'][self.transform_key]['quat'] 

    def getInitFrames(self) -> None:
        self.frame_init_trans = self.train_dataset['collections'][list(self.train_dataset['collections'].keys())[0]]['transforms_ini'][self.transform_key]['trans']
        self.frame_init_quat = self.train_dataset['collections'][list(self.train_dataset['collections'].keys())[0]]['transforms_ini'][self.transform_key]['quat']

    def computeTransRot(self) -> None:
        # Compute translation and rotation errors (This is from Eurico, did not change style)
        self.train_transform = getTransform(self.target_frame, self.source_child, self.train_dataset['collections'][list(self.train_dataset['collections'].keys())[0]]['transforms'])
        od = OrderedDict(sorted(self.test_dataset['collections'].items(), key=lambda t: int(t[0])))
        values_per_collection = {}
        for collection_key, collection in od.items():
            values_per_collection[collection_key] = {}
            
            test_transform = getTransform(self.target_frame, self.source_child, collection['transforms'])

            delta = np.dot(np.linalg.inv(self.train_transform), test_transform)

            deltaT = delta[0:3, 3]
            deltaR = matrixToRodrigues(delta[0:3, 0:3])

            values_per_collection[collection_key]['trans'] = np.linalg.norm(deltaT) * 1000
            values_per_collection[collection_key]['rot'] = np.linalg.norm(deltaR) * 180.0 / np.pi

        self.average_trans = sum(values_per_collection[collection_key]['trans'] for collection_key in values_per_collection) / len(values_per_collection)
        self.average_rot = sum(values_per_collection[collection_key]['rot'] for collection_key in values_per_collection) / len(values_per_collection)

    def computeFinalValues(self) -> None:
        self.dict[self.source_frame] = {} # init the dictionary of errors for this transformation
        self.dict[self.source_frame]['x'] = abs(self.frame_calibrated_trans[0] - self.frame_init_trans[0]) * 1000
        self.dict[self.source_frame]['y'] = abs(self.frame_calibrated_trans[1] - self.frame_init_trans[1]) * 1000
        self.dict[self.source_frame]['z'] = abs(self.frame_calibrated_trans[2] - self.frame_init_trans[2]) * 1000
        self.dict[self.source_frame]['roll'] = abs(self.r_cal - self.r_ini) * 180.0 / np.pi
        self.dict[self.source_frame]['pitch'] = abs(self.p_cal - self.p_ini) * 180.0 / np.pi
        self.dict[self.source_frame]['yaw'] = abs(self.p_cal - self.p_ini) * 180.0 / np.pi
        self.dict[self.source_frame]['Trans'] = self.average_trans
        self.dict[self.source_frame]['Rot'] = self.average_rot

    def eulerFromQuaternion(self, qx, qy, qz, qw) -> List[float]:
        """
        Convert a quaternion into euler angles (roll, pitch, yaw)
        roll is rotation around x in radians (counterclockwise)
        pitch is rotation around y in radians (counterclockwise)
        yaw is rotation around z in radians (counterclockwise)
        adapted from: https://automaticaddison.com/how-to-convert-a-quaternion-into-euler-angles-in-python/
        """
        t0 = +2.0 * (qw * qx + qy * qz)
        t1 = +1.0 - 2.0 * (qx * qx + qy * qy)
        roll_x = math.atan2(t0, t1)
        
        t2 = +2.0 * (qw * qy - qz * qx)
        t2 = +1.0 if t2 > +1.0 else t2
        t2 = -1.0 if t2 < -1.0 else t2
        pitch_y = math.asin(t2)
        
        t3 = +2.0 * (qw * qz + qx * qy)
        t4 = +1.0 - 2.0 * (qy * qy + qz * qz)
        yaw_z = math.atan2(t3, t4)
     
        return roll_x, pitch_y, yaw_z # in radians

    def saveToDict(self):
        self.getCalibratedFrames()
        self.r_cal, self.p_cal, self.y_cal = self.eulerFromQuaternion(self.frame_calibrated_quat[0],self.frame_calibrated_quat[1],self.frame_calibrated_quat[2],self.frame_calibrated_quat[3])
        self.getInitFrames()
        self.r_ini, self.p_ini, self.y_ini = self.eulerFromQuaternion(self.frame_init_quat[0],self.frame_init_quat[1],self.frame_init_quat[2],self.frame_init_quat[3])
        self.computeTransRot()
        self.computeFinalValues()

# -------------------------------------------------------------------------------
# --- FUNCTIONS
# -------------------------------------------------------------------------------
def evaluateTargetFrame(target_frame, source_child):
    try:
        train_transform = getTransform(target_frame, source_child, train_dataset['collections'][list(train_dataset['collections'].keys())[0]]['transforms'])
    except:
        print(f'Target frame {Fore.RED}{target_frame}{Style.RESET_ALL} is not in the transformation chain of {Fore.RED}{source_child}{Style.RESET_ALL}')
        sys.exit()

def loadArgJson(arg):
    f = open(arg, 'r')
    return json.load(f)

def argToTargetFrame(arg, train_dataset):
    if arg == None:
        # find the parent of the first frame in the first collection (e.g. base_link)
        transforms = train_dataset['collections'][list(train_dataset['collections'].keys())[0]]['transforms']
        for transform in transforms:
            if 'parent' in transforms[transform]:
                target_frame = transforms[transform]['parent']
                break
        else:
            target_frame = None
    else:
        target_frame = args['target_frame']
    
    return target_frame

def evaluateSourceFrame(source_frame, train_dataset):
    if source_frame in train_dataset['calibration_config']['additional_tfs']:
        transform_key = generateKey(train_dataset['calibration_config']['additional_tfs'][source_frame]['parent_link'], 
                                    train_dataset['calibration_config']['additional_tfs'][source_frame]['child_link'])
        source_child = train_dataset['calibration_config']['additional_tfs'][source_frame]['child_link']

    elif source_frame in train_dataset['calibration_config']['sensors']:
        transform_key = generateKey(train_dataset['calibration_config']['sensors'][source_frame]['parent_link'], 
                                    train_dataset['calibration_config']['sensors'][source_frame]['child_link'])
        source_child = train_dataset['calibration_config']['sensors'][source_frame]['child_link']
    else:
        print(f'Source frame {Fore.RED}{source_frame}{Style.RESET_ALL} in not a known frame!')

    return transform_key, source_child

# -------------------------------------------------------------------------------
# --- MAIN
# -------------------------------------------------------------------------------
if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("-train_json", "--train_json_file", help="Json file containing train input dataset.", type=str, required=True)
    ap.add_argument("-test_json", "--test_json_file", help="Json file containing test input dataset.", type=str, required=True)
    ap.add_argument("-tf", "--target_frame", help="Target transformation frame.", type=str, required=False)
    ap.add_argument("-sf", "--source_frame", help="Source transformation frame. If no frame is provided, computes all estimated frames.", type=str, required=False)
    # save results in a csv file
    ap.add_argument("-sfr", "--save_file_results", help="Output folder to where the results will be stored.", type=str, required=False)
    args = vars(ap.parse_args())

    # ---------------------------------------
    # --- INITIALIZATION Read calibration data from file
    # ---------------------------------------
    train_dataset = loadArgJson(args['train_json_file'])
    test_dataset = loadArgJson(args['test_json_file'])

    # ---------------------------------------
    # --- STEP 1: Calculate error values and append into a dict
    # ---------------------------------------
    errors_dict = {} # dictionary with all the errors
    target_frame = argToTargetFrame(args['target_frame'],train_dataset)

    if args['source_frame'] != None: # compute for a selected source frame
        source_frame = args['source_frame']
        transform_key, source_child = evaluateSourceFrame(source_frame, train_dataset)
        evaluateTargetFrame(target_frame, source_child)
        final_dict = FinalDictionary(train_dataset,test_dataset,transform_key,target_frame,source_frame,source_child,errors_dict)
        final_dict.saveToDict()
        
    else: # compute for all frames estimated in the calibration
        if checkAdditionalTfs(train_dataset):
            for additional_tf_key, additional_tf in train_dataset['calibration_config']['additional_tfs'].items():
                transform_key = generateKey(additional_tf['parent_link'], additional_tf['child_link'])
                source_child = additional_tf['child_link']
                evaluateTargetFrame(target_frame, source_child)
                final_dict = FinalDictionary(train_dataset,test_dataset,transform_key,target_frame,additional_tf_key,source_child,errors_dict)
                final_dict.saveToDict()

        for sensor_key, sensor in train_dataset['calibration_config']['sensors'].items():
            transform_key = generateKey(sensor['parent_link'], sensor['child_link'])
            source_child = sensor['child_link']
            evaluateTargetFrame(target_frame, source_child)
            final_dict = FinalDictionary(train_dataset,test_dataset,transform_key,target_frame,sensor_key,source_child,errors_dict)
            final_dict.saveToDict()

    # -------------------------------------------------------------
    # STEP 2: Print output table
    # -------------------------------------------------------------
    if errors_dict:
        table = Table(errors_dict, args['save_file_results'])
        table.print_table()
        

