#!/usr/bin/env python3
"""
casts an optimization problem using an atom dataset file as input. Then calibrates by running the optimization.
"""
import argparse
import copy
import json
import math
import os
import os.path
import random
import signal
import sys
from functools import partial

import atom_calibration.calibration.patterns_config as patterns
import atom_core.naming
import cv2
import numpy as np
# own packages
import OptimizationUtils.OptimizationUtils as OptimizationUtils
import ros_numpy
# 3rd-party
import rospy
import sensor_msgs.point_cloud2 as pc2
import tf
from atom_calibration.calibration.getters_and_setters import (
    getterCameraIntrinsics, getterTransform, setterCameraIntrinsics,
    setterTransform)
from atom_calibration.calibration.objective_function import (
    getPointsInSensorAsNPArray, objectiveFunction)
from atom_calibration.collect.label_messages import (
    convertDepthImage16UC1to32FC1, convertDepthImage32FC1to16UC1,
    imageShowUInt16OrFloat32OrBool)
from atom_calibration.dataset_playback.depth_manual_labeling import (
    clickedPointsCallback, clickedPointsReset)
from atom_calibration.dataset_playback.visualization import (
    setupVisualization, visualizationFunction)
from atom_core.config_io import readXacroFile, uriReader
from atom_core.dataset_io import (NpEncoder, addNoiseToInitialGuess,
                                  createDataFile, filterCollectionsFromDataset,
                                  filterSensorsFromDataset,
                                  getPointCloudMessageFromDictionary,
                                  loadResultsJSON, walk)
from atom_core.naming import generateKey, generateName
from atom_core.utilities import waitForKeyPress, waitForKeyPress2
from colorama import Back, Fore, Style
from cv_bridge import CvBridge
from geometry_msgs.msg import PointStamped
from pynput import keyboard
from rospy_message_converter import message_converter
from sensor_msgs.msg import PointCloud2
from sqlalchemy import false

# global variavels

# var to select the index of the collection we want to see
global idx_collection
previous_selected_collection_key = None


# -------------------------------------------------------------------------------
# --- FUNCTIONS
# -------------------------------------------------------------------------------

# Daniel: I had to copy this functions because in the atom_core.dataset_io we are sorting the keys! We should not sort the keys!!!
def saveResultsJSON(output_file, dataset_in, freeze_dataset=False):
    if freeze_dataset:  # to make sure our changes only affect the dictionary to save
        dataset = copy.deepcopy(dataset_in)
    else:
        dataset = dataset_in
    output_folder = os.path.dirname(output_file)

    # Process the dataset to remove data from the data fields and, if needed, write the files.
    for collection_key, collection in dataset['collections'].items():
        for sensor_key, sensor in dataset['sensors'].items():
            createDataFile(dataset, collection_key, sensor,
                           sensor_key, output_folder)

        # Do the same for additional data topics ...
        # for description, sensor in dataset['additional_sensor_data'].items():
        #     createDataFile(dataset_in, collection_key, sensor, description, output_folder, 'additional_data')

    createJSONFile(output_file, dataset)  # write dictionary to json


def createJSONFile(output_file, input):
    """
    Creates the json file containing the results data.
    :param output_file: output file.
    :param input: input dictionary containing the data.
    """
    D = copy.deepcopy(input)
    walk(D)

    print("Saving the json output file to " + str(output_file) +
          ", please wait, it could take a while ...")
    f = open(output_file, 'w')
    # to get only four decimal places on the json file
    json.encoder.FLOAT_REPR = lambda f: ("%.6f" % f)
    # print >> f, json.dumps(D, indent=2, sort_keys=True)
    f.write(json.dumps(D, indent=2, cls=NpEncoder))

    f.close()
    print("Completed.")


def signal_handler(sig, frame, dataset, args):
    ans = input('Press S to save and Q to quit')
    if ans.lower() == 's':
        if '_metadata' in dataset:
            D = {'_metadata': dataset['_metadata'], 'sensors': dataset['sensors'],
                 'additional_sensor_data': dataset['additional_sensor_data'],
                 'collections': dataset['collections'], 'calibration_config': dataset['calibration_config']}
            print('Saving metadata in dataset.')
        else:
            D = {'sensors': dataset['sensors'],
                 'additional_sensor_data': dataset['additional_sensor_data'],
                 'collections': dataset['collections'], 'calibration_config': dataset['calibration_config']}
            print('Not saving metadata in dataset.')
        output_file = '/'.join(args['json_file'].split('/')
                               [:-1]) + '/dataset_corrected.json'
        saveResultsJSON(output_file, D, freeze_dataset=True)
        print(f'A new dataset was saved in {output_file}')
        # sys.exit(0)
    if ans.lower() == 'q':
        if '_metadata' in dataset:
            D = {'_metadata': dataset['_metadata'], 'sensors': dataset['sensors'],
                 'additional_sensor_data': dataset['additional_sensor_data'],
                 'collections': dataset['collections'], 'calibration_config': dataset['calibration_config']}
            print('Saving metadata in dataset.')
        else:
            D = {'sensors': dataset['sensors'],
                 'additional_sensor_data': dataset['additional_sensor_data'],
                 'collections': dataset['collections'], 'calibration_config': dataset['calibration_config']}
            print('Not saving metadata in dataset.')
        output_file = '/'.join(args['json_file'].split('/')
                               [:-1]) + '/dataset_corrected.json'
        saveResultsJSON(output_file, D, freeze_dataset=True)
        print(f'A new dataset was saved in {output_file}')
        sys.quit(0)


# keyboard listener
def key_pressed(key, selection, dataset, args):
    # Shortcut variables
    idx_collection = int(selection['collection_key'])
    idx_max_collection = len(dataset['collections'].keys()) - 1

    # Convert from type to string to keep uniform.
    key = str(key)

    if key == 'Key.right':  # Move to collection + 1.
        if idx_collection < idx_max_collection:
            selection['previous_collection_key'] = selection['collection_key']
            selection['collection_key'] = str(idx_collection + 1)
            print('Changed selected_collection_key to ' +
                  selection['collection_key'])
        else:
            print(Fore.RED + 'This is the last collection!!' + Fore.RESET)
    elif key == 'Key.left':  # Move to collection - 1.
        if idx_collection > 0:
            selection['previous_collection_key'] = selection['collection_key']
            selection['collection_key'] = str(idx_collection - 1)
            print('Changed selected_collection_key to ' +
                  selection['collection_key'])
        else:
            print(Fore.RED + 'This is the first collection!!' + Fore.RESET)
    elif key == "'s'":  # Saves dataset.
        output_file = '/'.join(args['json_file'].split('/')[:-1]) + '/dataset_corrected.json'

        # TODO why not use the standard in  atom_core.dataset_io.saveResultsJSON
        saveResultsJSON(output_file, dataset, freeze_dataset=True)
        # atom_core.dataset_io.saveResultsJSON(output_file, D, freeze_dataset = True)

        print('A new dataset was saved in ' + output_file)
    elif key == "'q'":  # Saves dataset and quits.
        output_file = '/'.join(args['json_file'].split('/')[:-1]) + '/dataset_corrected.json'

        # TODO why not use the standard in  atom_core.dataset_io.saveResultsJSON
        saveResultsJSON(output_file, dataset, freeze_dataset=True)
        # atom_core.dataset_io.saveResultsJSON(output_file, D, freeze_dataset = True)

        print('A new dataset was saved in ' + output_file)

        print('Exiting ...')
        selection['exit'] = True


def selected_points_callback(selected_point_cloud, models):
    global idx_collection
    selected_collection_key = list(models['dataset']['collections'].keys())[
        idx_collection]

    # Extract xyz coordinates from the selected points
    selected_idxs = []
    points_selected = pc2.read_points(selected_point_cloud)
    gen_selected_points = list(points_selected)

    # sensor from the point cloud
    sensor = list(models['dataset']['collections'][selected_collection_key]['labels'].keys())[
        int(gen_selected_points[0][4])]

    for point in gen_selected_points:
        selected_idxs.append(int(point[3]))

    idx_center = models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs']

    [idx_center.append(x) for x in selected_idxs if x not in idx_center]
    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs'] = idx_center

    if models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs'] != [] and \
            models['dataset']['collections'][selected_collection_key]['labels'][sensor]['detected'] == False:
        models['dataset']['collections'][selected_collection_key]['labels'][sensor]['detected'] = True


def selected_points_border_callback(selected_point_cloud, models):
    global idx_collection
    selected_collection_key = list(models['dataset']['collections'].keys())[
        idx_collection]

    # Extract xyz coordinates from the selected points
    selected_idxs = []
    points_selected = pc2.read_points(selected_point_cloud)
    gen_selected_points = list(points_selected)

    # sensor from the point cloud
    sensor = list(models['dataset']['collections'][selected_collection_key]['labels'].keys())[
        int(gen_selected_points[0][4])]

    for point in gen_selected_points:
        selected_idxs.append(int(point[3]))

    idx_center = models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs']
    idx_border = models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs_limit_points']

    [idx_center.append(x) for x in selected_idxs if x not in idx_center]
    [idx_border.append(x) for x in selected_idxs if x not in idx_border]

    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs'] = idx_center
    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs_limit_points'] = idx_border


def selected_points_remove_callback(selected_point_cloud, models):
    global idx_collection
    selected_collection_key = list(models['dataset']['collections'].keys())[
        idx_collection]

    # Extract xyz coordinates from the selected points
    selected_idxs = []
    points_selected = pc2.read_points(selected_point_cloud)
    gen_selected_points = list(points_selected)

    # sensor from the point cloud
    sensor = list(models['dataset']['collections'][selected_collection_key]['labels'].keys())[
        int(gen_selected_points[0][4])]

    for point in gen_selected_points:
        selected_idxs.append(int(point[3]))

    # remove these points from the idx and idxs_limit_points
    idx_center = models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs']
    idx_border = models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs_limit_points']

    idx_center_new = [x for x in idx_center if x not in selected_idxs]
    idx_border_new = [x for x in idx_border if x not in selected_idxs]

    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs'] = idx_center_new
    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs_limit_points'] = idx_border_new


def selected_points_clear_all_callback(selected_point_cloud, models):
    global idx_collection
    selected_collection_key = list(models['dataset']['collections'].keys())[
        idx_collection]

    # Extract xyz coordinates from the selected points
    selected_idxs = []
    points_selected = pc2.read_points(selected_point_cloud)
    gen_selected_points = list(points_selected)

    # sensor from the point cloud
    sensor = list(models['dataset']['collections'][selected_collection_key]['labels'].keys())[
        int(gen_selected_points[0][4])]

    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs'] = []
    models['dataset']['collections'][selected_collection_key]['labels'][sensor]['idxs_limit_points'] = []


# -------------------------------------------------------------------------------
# --- MAIN
# -------------------------------------------------------------------------------
def main():
    # var to select the index of the collection we want to see
    global idx_collection
    global previous_selected_collection_key
    global points

    # ---------------------------------------
    # --- Parse command line argument
    # ---------------------------------------

    # signal.signal(signal.SIGINT, signal_handler)
    # print('Press Ctrl+C')
    # signal.pause()

    ap = argparse.ArgumentParser()
    ap = OptimizationUtils.addArguments(ap)  # OptimizationUtils arguments
    ap.add_argument("-json", "--json_file",
                    help="Json file containing input dataset.", type=str, required=True)
    ap.add_argument("-v", "--verbose", help="Be verbose",
                    action='store_true', default=False)
    ap.add_argument("-rv", "--ros_visualization",
                    help="Publish ros visualization markers.", action='store_true')
    ap.add_argument("-si", "--show_images", help="shows images for each camera",
                    action='store_true', default=False)
    ap.add_argument("-oi", "--optimize_intrinsics", help="Adds camera instrinsics to the optimization",
                    action='store_true', default=False)
    ap.add_argument("-pof", "--profile_objective_function",
                    help="Runs and prints a profile of the objective function, then exits.",
                    action='store_true', default=False)
    ap.add_argument("-sr", "--sample_residuals",
                    help="Samples residuals", type=float, default=1)
    ap.add_argument("-ss", "--sample_seed", help="Sampling seed", type=int)
    ap.add_argument("-ajf", "--all_joints_fixed",
                    help="Assume all joints are fixed and because of that draw a single robot mesh. Overrides "
                         "automatic detection of static robot.",
                    action='store_true', default=False)
    ap.add_argument("-uic", "--use_incomplete_collections",
                    help="Remove any collection which does not have a detection for all sensors.",
                    action='store_true', default=False)
    ap.add_argument("-rpd", "--remove_partial_detections",
                    help="Remove detected labels which are only partial. Used or the Charuco.",
                    action='store_true', default=False)
    ap.add_argument("-nig", "--noisy_initial_guess", nargs=2, metavar=('translation', 'rotation'),
                    help="Percentage of noise to add to the initial guess atomic transformations set before.",
                    type=float, default=[0.0, 0.0]),
    ap.add_argument("-ssf", "--sensor_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a sensor name as input and '
                         'returns True or False to indicate if the sensor should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: name in ["left_laser", "frontal_camera"] , to load only '
                         'sensors left_laser and frontal_camera')
    ap.add_argument("-csf", "--collection_selection_function", default=None, type=lambda s: eval(s, globals()),
                    help='A string to be evaluated into a lambda function that receives a collection name as input and '
                         'returns True or False to indicate if the collection should be loaded (and used in the '
                         'optimization). The Syntax is lambda name: f(x), where f(x) is the function in python '
                         'language. Example: lambda name: int(name) > 5 , to load only collections 6, 7, and onward.')
    ap.add_argument("-phased", "--phased_execution", help="Stay in a loop before calling optimization, and in another "
                                                          "after calling the optimization. Good for debugging.",
                    action='store_true', default=False)
    ap.add_argument("-ipg", "--initial_pose_ghost",
                    help="Draw a ghost mesh with the systems initial pose. Good for debugging.",
                    action='store_true', default=False)
    ap.add_argument('-oj', '--output_json', help='Full path to output json file.', type=str, required=False,
                    default=None)
    ap.add_argument('-ox', '--output_xacro', help='Full path to output xacro file.', type=str, required=False,
                    default=None)
    ap.add_argument("-ow", "--overwrite",
                    help="Overwrites the data_corrected.json without asking for permission.", action='store_true')

    # Roslaunch adds two arguments (__name and __log) that break our parser. Lets remove those.
    arglist = [x for x in sys.argv[1:] if not x.startswith('__')]
    args = vars(ap.parse_args(args=arglist))

    # ---------------------------------------
    # --- INITIALIZATION Read data from file
    # ---------------------------------------
    # Loads a json file containing the detections. Returned json_file has path resolved by urireader.
    dataset, json_file = loadResultsJSON(
        args['json_file'], args['collection_selection_function'])
    # d= copy.deepcopy(dataset['collections']['0']['data']["depth_camera_1"])
    # del d['data_file']
    # msg_33 = message_converter.convert_dictionary_to_ros_message('sensor_msgs/Image', d)
    # bridge=CvBridge()
    # image_33=bridge.imgmsg_to_cv2(msg_33, desired_encoding='passthrough')
    # imageShowUInt16OrFloat32OrBool(image_33, "dataset_playback_load_results")
    # cv2.waitKey(5)
    # exit(0)
    # ---------------------------------------
    # --- Filter some collections and / or sensors from the dataset
    # ---------------------------------------
    dataset = filterCollectionsFromDataset(dataset, args)  # filter collections
    output_file = '/'.join(args['json_file'].split('/')
                           [:-1]) + '/dataset_corrected.json'
    if os.path.exists(output_file) and args['json_file'] != output_file and not args['overwrite']:
        ans = input(
            'The file dataset_corrected.json already exists. Do you want to overwrite? (Y/n)')
        if ans.lower() == 'n':
            sys.exit(0)

    # Create the chessboard dataset must be called before deleting the sensors to cope with the possibility of
    # setting up an optimization without cameras. For now we MUST have a camera to estimate the initial parameters
    # related to the pattern pose (we use solve PNP for a camera).
    # TODO: Solve this strange dependency.
    dataset['patterns'] = patterns.createPatternLabels(args, dataset)

    dataset = filterSensorsFromDataset(dataset, args)  # filter sensors

    print('Loaded dataset containing ' + str(len(dataset['sensors'].keys())) + ' sensors and ' + str(
        len(dataset['collections'].keys())) + ' collections.')

    # ---------------------------------------
    # --- Store initial values for transformations to be optimized
    # ---------------------------------------
    for collection_key, collection in dataset['collections'].items():
        initial_transform_key = generateName('transforms', suffix='ini')
        collection[initial_transform_key] = copy.deepcopy(
            collection['transforms'])
        for transform_key, transform in collection[initial_transform_key].items():
            transform['parent'] = generateName(
                transform['parent'], suffix='ini')
            transform['child'] = generateName(transform['child'], suffix='ini')

    # ---------------------------------------
    # --- Define selected collection key.
    # ---------------------------------------
    # For the getters we only need to get one collection. Lets take the first key on the dictionary and always get that
    # transformation.
    idx_collection = 0
    collections_list = list(dataset['collections'].keys())

    print(collections_list)
    selected_collection_key = collections_list[idx_collection]
    # print('Selected collection key is ' + str(selected_collection_key))

    # ---------------------------------------
    # --- SETUP OPTIMIZER: Create data models
    # ---------------------------------------
    opt = OptimizationUtils.Optimizer()
    opt.addDataModel('args', args)
    opt.addDataModel('dataset', dataset)

    # ---------------------------------------
    # --- SETUP OPTIMIZER: Add pattern(s) parameters
    # ---------------------------------------
    # Each Pattern will have the position (tx,ty,tz) and rotation (r1,r2,r3)

    # Pattern not fixed -------------------------
    if not dataset['calibration_config']['calibration_pattern']['fixed']:
        # If pattern is not fixed there will be a transform for each collection. To tackle this reference link called
        # according to what is on the dataset['calibration_config']['calibration_pattern']['link'] is prepended with
        # a "c<collection_name>" appendix. This is done automatically for the collection['transforms'] when
        # publishing ROS, but we must add this to the parameter name.
        parent = dataset['calibration_config']['calibration_pattern']['parent_link']
        child = dataset['calibration_config']['calibration_pattern']['link']
        transform_key = atom_core.naming.generateKey(parent, child)

        # iterate all collections
        for collection_key, collection in dataset['collections'].items():

            # Set transform using the initial estimate of the transformations.
            initial_estimate = dataset['patterns']['transforms_initial'][collection_key]
            if not initial_estimate['detected'] or not parent == initial_estimate['parent'] or \
                    not child == initial_estimate['child']:
                raise ValueError(
                    'Cannot set initial estimate for pattern at collection ' + collection_key)

            collection['transforms'][transform_key] = {'parent': parent, 'child': child,
                                                       'trans': initial_estimate['trans'],
                                                       'quat': initial_estimate['quat']}

    else:  # fixed pattern ---------------------------------------------------------------------------------------------
        # if pattern is fixed it will not be replicated for all collections , i.e. there will be a single
        # reference link called according to what is on the dataset['calibration_config']['calibration_pattern'][
        # 'link']
        parent = dataset['calibration_config']['calibration_pattern']['parent_link']
        child = dataset['calibration_config']['calibration_pattern']['link']
        transform_key = atom_core.naming.generateKey(parent, child)

        # Set transform using the initial estimate of the transformations.
        initial_estimate = dataset['patterns']['transforms_initial'][selected_collection_key]
        if not initial_estimate['detected'] or not parent == initial_estimate['parent'] or \
                not child == initial_estimate['child']:
            raise ValueError(
                'Cannot set initial estimate for pattern at collection ' + collection_key)

        # The pattern is fixed but we have a replicated transform for each collection. Lets add those.
        for collection_key, collection in dataset['collections'].items():
            collection['transforms'][transform_key] = {'parent': parent, 'child': child,
                                                       'trans': initial_estimate['trans'],
                                                       'quat': initial_estimate['quat']}

    # ---------------------------------------
    # --- DEFINE THE VISUALIZATION FUNCTION
    # ---------------------------------------
    # d= copy.deepcopy(dataset['collections']['0']['data']["depth_camera_1"])
    # del d['data_file']
    # msg_33 = message_converter.convert_dictionary_to_ros_message('sensor_msgs/Image', d)
    # bridge=CvBridge()
    # image_33=bridge.imgmsg_to_cv2(msg_33, desired_encoding='passthrough')
    # imageShowUInt16OrFloat32OrBool(image_33, "dataset_playback")
    # cv2.waitKey(5)

    print("Configuring visualization ... ")
    graphics = setupVisualization(dataset, args, selected_collection_key)
    opt.addDataModel('graphics', graphics)

    # ---------------------------------------------
    # --- SUBSCRIBERS TO PLUGINS
    # ---------------------------------------------

    # ---------------------------------------
    # --- lidar3d modality
    # ---------------------------------------

    # Define subscriber to receive the selected points
    rospy.Subscriber("/rviz_selected_points", PointCloud2,
                     partial(selected_points_callback, models=opt.data_models), queue_size=1, buff_size=52428800)
    rospy.Subscriber("/rviz_selected_border_points", PointCloud2,
                     partial(selected_points_border_callback, models=opt.data_models), queue_size=1, buff_size=52428800)
    rospy.Subscriber("/rviz_selected_remove_points", PointCloud2,
                     partial(selected_points_remove_callback, models=opt.data_models), queue_size=1, buff_size=52428800)
    rospy.Subscriber("/rviz_selected_clear_all_points", PointCloud2,
                     partial(selected_points_clear_all_callback, models=opt.data_models), queue_size=1,
                     buff_size=52428800)

    # ---------------------------------------
    # --- Depth modality
    # ---------------------------------------

    # Subscriber for the image_click plugin
    # this stores the pixel coordinates of clicked points per collection, and per sensor key
    clicked_points = {
        collection_key: {} for collection_key in dataset['collections']}

    # Initialize clicked points for all collections and sensors
    for collection_key in dataset['collections']:
        for sensor_key, sensor in dataset['sensors'].items():
            if sensor['modality'] == 'depth':
                clickedPointsReset(clicked_points, collection_key, sensor_key)

    # Create a subscriber for each depth sensor
    selection = {'collection_key': selected_collection_key, 'previous_collection_key': previous_selected_collection_key,
                 'exit': False}
    for sensor_key, sensor in dataset['sensors'].items():
        if sensor['modality'] == 'depth':
            points_topic = dataset['sensors'][sensor_key]['topic'] + '/labeled/mouse_click'
            rospy.Subscriber(points_topic, PointStamped,
                             partial(clickedPointsCallback, clicked_points=clicked_points,
                                     dataset=dataset, sensor_key=sensor_key, selection=selection))

    # ---------------------------------------
    # --- Define callback to change idx_collection
    # ---------------------------------------
    key_pressed_partial = partial(key_pressed, selection=selection, dataset=opt.data_models['dataset'], args=args)
    listener = keyboard.Listener(
        on_press=key_pressed_partial)
    listener.start()

    # signal_handler_partial = partial(
    #     signal_handler, dataset=opt.data_models['dataset'], args=args)
    # signal.signal(signal.SIGINT, signal_handler_partial)

    rate = rospy.Rate(30)  # 30hz
    while not rospy.is_shutdown() and not selection['exit']:
        # selected_collection_key = collections_list[idx_collection]
        # selection['collection_key'] = selected_collection_key

        # print('Selected collection key is ' + selection['collection_key'])
        visualizationFunction(opt.data_models, selection=selection, clicked_points=clicked_points)
        rate.sleep()


if __name__ == "__main__":
    main()
